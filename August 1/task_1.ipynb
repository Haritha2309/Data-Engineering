{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZlCy3lS6-x1O"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('employees').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "data = [\n",
        "Row(EmpID=101, Name=\"Ravi\", Department=\"Engineering\", Project=\"AI Engine\",\n",
        "Salary=95000, HoursPerWeek=42),\n",
        "Row(EmpID=102, Name=\"Sneha\", Department=\"Engineering\", Project=\"Data Platform\",\n",
        "Salary=87000, HoursPerWeek=45),\n",
        "Row(EmpID=103, Name=\"Kabir\", Department=\"Marketing\", Project=\"Product Launch\",\n",
        "Salary=65000, HoursPerWeek=40),\n",
        "Row(EmpID=104, Name=\"Anita\", Department=\"Sales\", Project=\"Client Outreach\",\n",
        "Salary=70000, HoursPerWeek=38),\n",
        "Row(EmpID=105, Name=\"Divya\", Department=\"Engineering\", Project=\"AI Engine\",\n",
        "Salary=99000, HoursPerWeek=48),\n",
        "Row(EmpID=106, Name=\"Amit\", Department=\"Marketing\", Project=\"Social Media\",\n",
        "Salary=62000, HoursPerWeek=35),\n",
        "Row(EmpID=107, Name=\"Priya\", Department=\"HR\", Project=\"Policy Revamp\",\n",
        "Salary=58000, HoursPerWeek=37),\n",
        "Row(EmpID=108, Name=\"Manav\", Department=\"Sales\", Project=\"Lead Gen\", Salary=73000,\n",
        "HoursPerWeek=41),\n",
        "Row(EmpID=109, Name=\"Neha\", Department=\"Engineering\", Project=\"Security Suite\",\n",
        "Salary=91000, HoursPerWeek=46),\n",
        "Row(EmpID=110, Name=\"Farah\", Department=\"HR\", Project=\"Onboarding\", Salary=60000,\n",
        "HoursPerWeek=36)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data)\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTWDAuSn_hNe",
        "outputId": "3707a4f5-3abf-4f70-8113-4ee629e9b13d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|EmpID|Name |Department |Project        |Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|101  |Ravi |Engineering|AI Engine      |95000 |42          |\n",
            "|102  |Sneha|Engineering|Data Platform  |87000 |45          |\n",
            "|103  |Kabir|Marketing  |Product Launch |65000 |40          |\n",
            "|104  |Anita|Sales      |Client Outreach|70000 |38          |\n",
            "|105  |Divya|Engineering|AI Engine      |99000 |48          |\n",
            "|106  |Amit |Marketing  |Social Media   |62000 |35          |\n",
            "|107  |Priya|HR         |Policy Revamp  |58000 |37          |\n",
            "|108  |Manav|Sales      |Lead Gen       |73000 |41          |\n",
            "|109  |Neha |Engineering|Security Suite |91000 |46          |\n",
            "|110  |Farah|HR         |Onboarding     |60000 |36          |\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"employees_local\")"
      ],
      "metadata": {
        "id": "ZzYFt-_7_-Zn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceGlobalTempView(\"employees_global\")"
      ],
      "metadata": {
        "id": "AbZY3wNtADaJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART A"
      ],
      "metadata": {
        "id": "NcVjk8pMAHJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List all employees working on the \"AI Engine\" project."
      ],
      "metadata": {
        "id": "3n33QDaQAJFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from employees_local where Project = 'AI Engine' \").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCCUup-bAL8y",
        "outputId": "5fd3f34c-f6bc-4fa2-d2f4-042838e7888e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------+------+------------+\n",
            "|EmpID| Name| Department|  Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------+------+------------+\n",
            "|  101| Ravi|Engineering|AI Engine| 95000|          42|\n",
            "|  105|Divya|Engineering|AI Engine| 99000|          48|\n",
            "+-----+-----+-----------+---------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show all employees from the \"Marketing\" department with salaries greater than\n",
        "60,000."
      ],
      "metadata": {
        "id": "MnfmID4aArqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from employees_local where Department = 'Marketing' and salary >60000\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgbFEH38Au-L",
        "outputId": "1fb65e11-bbf9-40a0-b3fc-38df0319bf63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+--------------+------+------------+\n",
            "|EmpID| Name|Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+----------+--------------+------+------------+\n",
            "|  103|Kabir| Marketing|Product Launch| 65000|          40|\n",
            "|  106| Amit| Marketing|  Social Media| 62000|          35|\n",
            "+-----+-----+----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the average salary for each department."
      ],
      "metadata": {
        "id": "XjPd7nt7A_5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select department,avg(salary) as average from employees_local group by department').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2BbGRG_BB4d",
        "outputId": "566c2552-0c4c-41b7-be49-e91f77f9906b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+\n",
            "| department|average|\n",
            "+-----------+-------+\n",
            "|      Sales|71500.0|\n",
            "|Engineering|93000.0|\n",
            "|  Marketing|63500.0|\n",
            "|         HR|59000.0|\n",
            "+-----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the top 3 highest paid employees overall."
      ],
      "metadata": {
        "id": "EpY6voZPCCfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from employees_local order by salary desc limit 3').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrtgGdm_CFmr",
        "outputId": "3ef99876-e9ca-4aba-9b17-0cd80246af5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find employees who work more than 40 hours per week."
      ],
      "metadata": {
        "id": "sWYDLFr_DTy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from employees_local where hoursperweek >40').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmXLz_-ZDWYd",
        "outputId": "aaa4e045-1d7e-487a-daff-b28dd14ede76"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering| Data Platform| 87000|          45|\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  108|Manav|      Sales|      Lead Gen| 73000|          41|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group by project and display the number of employees per project."
      ],
      "metadata": {
        "id": "G_tEU74gDjDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select project, count(empid)as count from employees_local group by project').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0LTTzaIDlXH",
        "outputId": "aeab6085-dbd9-4bc4-c217-6c819a179454"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+\n",
            "|        project|count|\n",
            "+---------------+-----+\n",
            "|  Data Platform|    1|\n",
            "|      AI Engine|    2|\n",
            "| Product Launch|    1|\n",
            "|Client Outreach|    1|\n",
            "| Security Suite|    1|\n",
            "|  Policy Revamp|    1|\n",
            "|       Lead Gen|    1|\n",
            "|   Social Media|    1|\n",
            "|     Onboarding|    1|\n",
            "+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the local view. Try querying again — what happens?"
      ],
      "metadata": {
        "id": "AXAfOEGbEjtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.dropTempView('employees_local')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3gPqCzWEr6C",
        "outputId": "8bb672e8-6dc9-43b2-8103-0a8767871982"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from employees_local').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "N6zFA5WSEyFL",
        "outputId": "49b77646-aa9f-4b71-f8ae-3422a0cf0811"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `employees_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [employees_local], [], false\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1306909798.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select * from employees_local'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `employees_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [employees_local], [], false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART B"
      ],
      "metadata": {
        "id": "RkDnpndoE6O9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve all \"HR\" employees working fewer than 38 hours/week."
      ],
      "metadata": {
        "id": "hee6qOMUE_sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from global_temp.employees_global where department = 'HR' and hoursperweek<38\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NfNmh2bFCqw",
        "outputId": "3df98c71-7136-4ba7-aa12-f4b1b5ca76cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+-------------+------+------------+\n",
            "|EmpID| Name|Department|      Project|Salary|HoursPerWeek|\n",
            "+-----+-----+----------+-------------+------+------------+\n",
            "|  107|Priya|        HR|Policy Revamp| 58000|          37|\n",
            "|  110|Farah|        HR|   Onboarding| 60000|          36|\n",
            "+-----+-----+----------+-------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the total salary payout for each department."
      ],
      "metadata": {
        "id": "ASTFlIhAHW-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select department,sum(salary)as totalpay from global_temp.employees_global group by department').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVvOs4rqHZDQ",
        "outputId": "1db9440b-9651-4743-e36f-a20168663f09"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+\n",
            "| department|totalpay|\n",
            "+-----------+--------+\n",
            "|      Sales|  143000|\n",
            "|Engineering|  372000|\n",
            "|  Marketing|  127000|\n",
            "|         HR|  118000|\n",
            "+-----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each employee, add a derived column Status :\n",
        "If HoursPerWeek > 45 → 'Overworked'\n",
        "Otherwise → 'Normal'"
      ],
      "metadata": {
        "id": "6wvFEzdbHng6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "select *,\n",
        "CASE\n",
        "  WHEN HoursPerWeek >45 then 'overworked'\n",
        "  ELSE 'normal'\n",
        "END AS status\n",
        "from global_temp.employees_global\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-uOyyG5HshQ",
        "outputId": "a402fd31-c4cd-4bf6-8169-977c344ba687"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------------+------+------------+----------+\n",
            "|EmpID| Name| Department|        Project|Salary|HoursPerWeek|    status|\n",
            "+-----+-----+-----------+---------------+------+------------+----------+\n",
            "|  101| Ravi|Engineering|      AI Engine| 95000|          42|    normal|\n",
            "|  102|Sneha|Engineering|  Data Platform| 87000|          45|    normal|\n",
            "|  103|Kabir|  Marketing| Product Launch| 65000|          40|    normal|\n",
            "|  104|Anita|      Sales|Client Outreach| 70000|          38|    normal|\n",
            "|  105|Divya|Engineering|      AI Engine| 99000|          48|overworked|\n",
            "|  106| Amit|  Marketing|   Social Media| 62000|          35|    normal|\n",
            "|  107|Priya|         HR|  Policy Revamp| 58000|          37|    normal|\n",
            "|  108|Manav|      Sales|       Lead Gen| 73000|          41|    normal|\n",
            "|  109| Neha|Engineering| Security Suite| 91000|          46|overworked|\n",
            "|  110|Farah|         HR|     Onboarding| 60000|          36|    normal|\n",
            "+-----+-----+-----------+---------------+------+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count the total number of employees working on each \"Project\" ."
      ],
      "metadata": {
        "id": "ghVdTFlyIpHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select project,count(empid) from global_temp.employees_global group by project').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIzsIiFUIrtz",
        "outputId": "8ad72052-4fe2-43ed-ecf3-ba67a04781ab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------------+\n",
            "|        project|count(empid)|\n",
            "+---------------+------------+\n",
            "|  Data Platform|           1|\n",
            "|      AI Engine|           2|\n",
            "| Product Launch|           1|\n",
            "|Client Outreach|           1|\n",
            "| Security Suite|           1|\n",
            "|  Policy Revamp|           1|\n",
            "|       Lead Gen|           1|\n",
            "|   Social Media|           1|\n",
            "|     Onboarding|           1|\n",
            "+---------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List employees whose salary is above the average salary in their department."
      ],
      "metadata": {
        "id": "ytpV4SqWJ9a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from global_temp.employees_global where salary >(select avg(salary) from global_temp.employees_global)').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDCXbKsMKABz",
        "outputId": "1536d238-8f9c-4c85-9056-d5fe40b24731"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering| Data Platform| 87000|          45|\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List employees whose salary is above the average salary in their department."
      ],
      "metadata": {
        "id": "LaM5v63aKYdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_spark = SparkSession.builder.appName('new').getOrCreate()"
      ],
      "metadata": {
        "id": "IWdEvqCrKava"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_spark.sql('select * from global_temp.employees_global').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5SJwPckKmne",
        "outputId": "ccc4d368-cb2d-4d26-9912-d75046437e91"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|EmpID| Name| Department|        Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|  101| Ravi|Engineering|      AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering|  Data Platform| 87000|          45|\n",
            "|  103|Kabir|  Marketing| Product Launch| 65000|          40|\n",
            "|  104|Anita|      Sales|Client Outreach| 70000|          38|\n",
            "|  105|Divya|Engineering|      AI Engine| 99000|          48|\n",
            "|  106| Amit|  Marketing|   Social Media| 62000|          35|\n",
            "|  107|Priya|         HR|  Policy Revamp| 58000|          37|\n",
            "|  108|Manav|      Sales|       Lead Gen| 73000|          41|\n",
            "|  109| Neha|Engineering| Security Suite| 91000|          46|\n",
            "|  110|Farah|         HR|     Onboarding| 60000|          36|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BONUS"
      ],
      "metadata": {
        "id": "08J3QFtzKyf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a window function to assign rank to employees within each department based\n",
        "on salary."
      ],
      "metadata": {
        "id": "R11cQmbOK3Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select *,rank() over(partition by department order by salary desc) as rank from global_temp.employees_global').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFNxigx5K5RW",
        "outputId": "ea6383ac-d307-4e5b-9154-d6a3fcd55ab7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------------+------+------------+----+\n",
            "|EmpID| Name| Department|        Project|Salary|HoursPerWeek|rank|\n",
            "+-----+-----+-----------+---------------+------+------------+----+\n",
            "|  105|Divya|Engineering|      AI Engine| 99000|          48|   1|\n",
            "|  101| Ravi|Engineering|      AI Engine| 95000|          42|   2|\n",
            "|  109| Neha|Engineering| Security Suite| 91000|          46|   3|\n",
            "|  102|Sneha|Engineering|  Data Platform| 87000|          45|   4|\n",
            "|  110|Farah|         HR|     Onboarding| 60000|          36|   1|\n",
            "|  107|Priya|         HR|  Policy Revamp| 58000|          37|   2|\n",
            "|  103|Kabir|  Marketing| Product Launch| 65000|          40|   1|\n",
            "|  106| Amit|  Marketing|   Social Media| 62000|          35|   2|\n",
            "|  108|Manav|      Sales|       Lead Gen| 73000|          41|   1|\n",
            "|  104|Anita|      Sales|Client Outreach| 70000|          38|   2|\n",
            "+-----+-----+-----------+---------------+------+------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create another view (local or global) that only contains \"Engineering\"\n",
        "employees."
      ],
      "metadata": {
        "id": "FW60T2qZLiWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from global_temp.employees_global where department='Engineering'\").createOrReplaceTempView('Engineering')"
      ],
      "metadata": {
        "id": "RgiGLw_CLkrC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from engineering').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L_WtwprMAVi",
        "outputId": "59b634a7-441c-4f7d-8236-0daef3a3d628"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering| Data Platform| 87000|          45|\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a SQL view that filters out all employees working < 38 hours and saves\n",
        "it as \"active_employees\""
      ],
      "metadata": {
        "id": "fUFOYAuEMGqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from global_temp.employees_global where hoursperweek>38').createOrReplaceTempView('active_employees')"
      ],
      "metadata": {
        "id": "4jLZ5gzYMJRu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from active_employees').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMMT_OWRMY5M",
        "outputId": "76c8cb86-8647-4cab-aa1c-c69e47583957"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering| Data Platform| 87000|          45|\n",
            "|  103|Kabir|  Marketing|Product Launch| 65000|          40|\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  108|Manav|      Sales|      Lead Gen| 73000|          41|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}